{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import isfile\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "from random import shuffle\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.initializers import Constant\n",
    "import tensorflow as tf\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.models import Model\n",
    "import math\n",
    "\n",
    "from PIL import Image as pil_image\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (112,96,3)\n",
    "num_classes = 10575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lfw_list(index_file_path):\n",
    "    with open(index_file_path, 'rb') as index_file:\n",
    "        split_lines = [ln.decode().strip().split('\\t') for ln in index_file]\n",
    "    return split_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.listdir('../datasets/lfw/all_masked_bbox/'))\n",
    "\n",
    "\n",
    "data = get_lfw_list('../datasets/lfw/pairs.txt')\n",
    "data = data[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John_Bolton', '6', '7']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63799e3507048fda7d49efbfc33d294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[5555])\n",
    "test_X = []\n",
    "pair1 = []\n",
    "pair2 = []\n",
    "label = []\n",
    "\n",
    "for pairs in tqdm(data):\n",
    "    if len(pairs)==3:\n",
    "        number = str(pairs[1])\n",
    "        if len(number)==1:number = '000'+number\n",
    "        if len(number)==2:number = '00'+number\n",
    "        if len(number)==3:number = '0'+number\n",
    "        pair1_path = str(pairs[0])+':'+number+'.jpg'\n",
    "        number = str(pairs[2])\n",
    "        if len(number)==1:number = '000'+number\n",
    "        if len(number)==2:number = '00'+number\n",
    "        if len(number)==3:number = '0'+number\n",
    "        pair2_path = str(pairs[0])+':'+number+'.jpg'\n",
    "        \n",
    "        pair1.append(pair1_path)\n",
    "        pair2.append(pair2_path)\n",
    "        label.append(1)\n",
    "        \n",
    "        test_X.append(pair1_path)\n",
    "        test_X.append(pair2_path)\n",
    "    if len(pairs)==4:\n",
    "        number = str(pairs[1])\n",
    "        if len(number)==1:number = '000'+number\n",
    "        if len(number)==2:number = '00'+number\n",
    "        if len(number)==3:number = '0'+number\n",
    "        pair1_path = str(pairs[0])+':'+number+'.jpg'\n",
    "        number = str(pairs[3])\n",
    "        if len(number)==1:number = '000'+number\n",
    "        if len(number)==2:number = '00'+number\n",
    "        if len(number)==3:number = '0'+number\n",
    "        pair2_path = str(pairs[2])+':'+number+'.jpg'\n",
    "        \n",
    "        pair1.append(pair1_path)\n",
    "        pair2.append(pair2_path)\n",
    "        label.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=pair1, columns=['pair1'])\n",
    "df['pair2'] = pair2\n",
    "df['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair1</th>\n",
       "      <th>pair2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akhmed_Zakayev:0001.jpg</td>\n",
       "      <td>Akhmed_Zakayev:0003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akhmed_Zakayev:0002.jpg</td>\n",
       "      <td>Akhmed_Zakayev:0003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amber_Tamblyn:0001.jpg</td>\n",
       "      <td>Amber_Tamblyn:0002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anders_Fogh_Rasmussen:0001.jpg</td>\n",
       "      <td>Anders_Fogh_Rasmussen:0003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anders_Fogh_Rasmussen:0001.jpg</td>\n",
       "      <td>Anders_Fogh_Rasmussen:0004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            pair1                           pair2  label\n",
       "0         Akhmed_Zakayev:0001.jpg         Akhmed_Zakayev:0003.jpg      1\n",
       "1         Akhmed_Zakayev:0002.jpg         Akhmed_Zakayev:0003.jpg      1\n",
       "2          Amber_Tamblyn:0001.jpg          Amber_Tamblyn:0002.jpg      1\n",
       "3  Anders_Fogh_Rasmussen:0001.jpg  Anders_Fogh_Rasmussen:0003.jpg      1\n",
       "4  Anders_Fogh_Rasmussen:0001.jpg  Anders_Fogh_Rasmussen:0004.jpg      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(len(df)):\n",
    "    pair=[]\n",
    "    pair.append(df['pair1'].iloc[i])\n",
    "    pair.append(df['pair2'].iloc[i])\n",
    "    test.append(pair)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import img_to_array,array_to_img\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n",
    ")\n",
    "\n",
    "def strong_aug(p=0.7):\n",
    "    return Compose([\n",
    "        #RandomRotate90(),\n",
    "        #Flip(),\n",
    "        #HorizontalFlip(),\n",
    "        #OneOf([\n",
    "        #    IAAAdditiveGaussianNoise()\n",
    "        #], p=0.3),\n",
    "        #OneOf([\n",
    "        #    MotionBlur(p=0.3),\n",
    "        #    MedianBlur(blur_limit=1, p=0.3),\n",
    "        #    Blur(blur_limit=1, p=0.3),\n",
    "        #], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=30, p=0.5,border_mode=0),\n",
    "        #CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.35),\n",
    "        #OneOf([\n",
    "        #    IAASharpen(),\n",
    "        #    IAAEmboss(),\n",
    "        #], p=0.3),\n",
    "    ], p=p)\n",
    "\n",
    "aug = strong_aug(p=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = shape\n",
    "\n",
    "def read_cropped_image(p, augment):\n",
    "    \"\"\"\n",
    "    @param p : the name of the picture to read\n",
    "    @param augment: True/False if data augmentation should be performed\n",
    "    @return a numpy array with the transformed image\n",
    "    \"\"\"\n",
    "    # Read the image, transform to black and white and comvert to numpy array\n",
    "    img   = read_raw_image(p)#.convert('L')\n",
    "    img   = img_to_array(img)\n",
    "        \n",
    "    img   = img.astype('uint8')\n",
    "    \n",
    "    \n",
    "    if img.shape[2] == 1:\n",
    "        img = np.stack((img[..., 0],) * 3, axis=-1)\n",
    "    \n",
    "    if augment:\n",
    "        augmented = aug(image=img)\n",
    "        img = augmented['image']\n",
    "\n",
    "    \n",
    "    img = cv2.resize(img,(img_shape[1],img_shape[0]))\n",
    "\n",
    "    img   = img.astype('float64')\n",
    "    #img = img.astype('uint8')\n",
    "    # Normalize to zero mean and unit variance\n",
    "    img  -= np.mean(img, keepdims=True)\n",
    "    img  /= np.std(img, keepdims=True) #+ K.epsilon()\n",
    "    #img = img.reshape(img.shape[0],img.shape[1],1)\n",
    "    \n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL HEREEEE\n",
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "backbone = ResNet50(input_shape=shape, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Angular_loss import *\n",
    "\n",
    "model = create_model(shape,backbone,64e-2,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model', 'datasets', 'state-of-art']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-UNMASKED-112x112-3.826-0.888.model')\n",
    "#Model 3\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-UNMASKED-MASKED-0.9650-0.23.model')\n",
    "#Model 1\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-MASKED-112x112-23-12.932-0.020-20190424_110959.model')\n",
    "#Model Progressive + masked\n",
    "model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-PROGRESSIVE_MASK-112x96-20-6.109-0.823.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 112, 96, 3)        0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 4, 3, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_with__arcface_loss_5 ( (None, 10575)             21657600  \n",
      "=================================================================\n",
      "Total params: 45,253,504\n",
      "Trainable params: 45,196,288\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 112, 96, 3)        0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 4, 3, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2048)              8192      \n",
      "=================================================================\n",
      "Total params: 23,595,904\n",
      "Trainable params: 23,538,688\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_name = model.layers[-2].name\n",
    "model = Model(inputs=model.input,\n",
    "                        outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestingGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs,batch_size=32, dim=(112,112) ,n_classes=num_classes,n_channels=3,\n",
    "                 shuffle=False,augmentation=False):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.list_IDs = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.augmentation = augmentation\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor((len(self.list_IDs) / self.batch_size) ))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        \n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = read_cropped_image(ID,self.augmentation)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n",
      "5998\n",
      "11998\n"
     ]
    }
   ],
   "source": [
    "tr = os.listdir('../datasets/lfw/bbox/')\n",
    "final_test = []\n",
    "\n",
    "for pairs in test:\n",
    "    if pairs[0] in tr:\n",
    "        if pairs[1] in tr:\n",
    "            final_test.append(pairs[0])\n",
    "            final_test.append(pairs[1])\n",
    "\n",
    "print(len(test))\n",
    "print(len(test_X))\n",
    "print(len(final_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n",
      "5999\n"
     ]
    }
   ],
   "source": [
    "x1 = []\n",
    "x2 = []\n",
    "\n",
    "for i in range(0,len(final_test),2):\n",
    "    x1.append(final_test[i])\n",
    "    x2.append(final_test[i+1])\n",
    "    \n",
    "\n",
    "print(len(x1))\n",
    "print(len(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999/5999 [==============================] - 81s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "params = {'dim': (img_shape[0],img_shape[1]),\n",
    "          'batch_size': 1,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': False\n",
    "             }\n",
    "\n",
    "TRAIN_PATH = '../datasets/lfw/bbox/'\n",
    "\n",
    "def expand_path(p):\n",
    "    if isfile(TRAIN_PATH + str(p)): return TRAIN_PATH + str(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "def read_raw_image(p):\n",
    "    img = pil_image.open(expand_path(p))\n",
    "    #if p in rotate: img = img.rotate(180)\n",
    "    return img\n",
    "\n",
    "testing_generator = TestingGenerator(x1 ,**params,augmentation=False)\n",
    "\n",
    "features1 = model.predict_generator(\n",
    "        generator=testing_generator,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = ResNet50(input_shape=shape, weights='imagenet', include_top=False)\n",
    "model = create_model(shape,backbone,64e-2,num_classes)\n",
    "\n",
    "#Model 2\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-UNMASKED-112x112-3.826-0.888.model')\n",
    "#Model 3\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-UNMASKED-MASKED-0.9650-0.23.model')\n",
    "#Model 1\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-MASKED-112x112-23-12.932-0.020-20190424_110959.model')\n",
    "#Model Progressive + masked\n",
    "model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-PROGRESSIVE_MASK-112x96-20-6.109-0.823.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 112, 96, 3)        0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 4, 3, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_with__arcface_loss_6 ( (None, 10575)             21657600  \n",
      "=================================================================\n",
      "Total params: 45,253,504\n",
      "Trainable params: 45,196,288\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 112, 96, 3)        0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 4, 3, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2048)              8192      \n",
      "=================================================================\n",
      "Total params: 23,595,904\n",
      "Trainable params: 23,538,688\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_name = model.layers[-2].name\n",
    "model = Model(inputs=model.input,\n",
    "                        outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999/5999 [==============================] - 86s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = '../datasets/lfw/bbox_masked/'\n",
    "\n",
    "def expand_path(p):\n",
    "    if isfile(TRAIN_PATH + str(p)): return TRAIN_PATH + str(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "def read_raw_image(p):\n",
    "    img = pil_image.open(expand_path(p))\n",
    "    #if p in rotate: img = img.rotate(180)\n",
    "    return img\n",
    "\n",
    "testing_generator = TestingGenerator(x2 ,**params,augmentation=False)\n",
    "\n",
    "features2 = model.predict_generator(\n",
    "        generator=testing_generator,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_metric(x1, x2):\n",
    "    return np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "label = []\n",
    "\n",
    "for i in range(0,len(features1)):\n",
    "    feature_1 = features1[i]\n",
    "    feature_2 = features2[i]\n",
    "    distance = cosin_metric(feature_1,feature_2)\n",
    "    similarity.append(distance)\n",
    "    if x1[i].split(':')[0]==x2[i].split(':')[0]:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n",
      "5999\n"
     ]
    }
   ],
   "source": [
    "print(len(similarity))\n",
    "print(len(label))\n",
    "#similarity = np.absolute(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.445\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(len(similarity)):\n",
    "    if similarity[i]>threshold:\n",
    "        predicted = 1\n",
    "    else: predicted = 0\n",
    "    if predicted == label[i]:\n",
    "        accuracy += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9713285547591265\n"
     ]
    }
   ],
   "source": [
    "print(accuracy/len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n"
     ]
    }
   ],
   "source": [
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAD/VJREFUeJzt3W2MpWV9x/HvTyhYH0F2MHZ328G4tm5JG8mEYk1a6xrlwbC8kAZS62o3bmrQ2mJa1/qCRmOCtS3WxJJuBF0bC1Jqy0awlCDGtulSB1EUVsoUKTuFyigPfSA+bP33xblWx91hZ5gzc84s1/eTnJz7vu7rnPs/V4b5cd1Pm6pCktSfp427AEnSeBgAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4dO+4CjmTdunU1OTk57jIk6ahy2223fbOqJhbrt6YDYHJykunp6XGXIUlHlST/vpR+HgKSpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROrek7gfXkTe68fiz7ve/Sc8ayX0nL5wxAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcrLQLUivPxUOvo4A5CkTi0aAEmuTPJQkq/Oa/tAkq8luSPJ3yQ5Yd62dyWZSXJ3ktfMaz+ztc0k2bnyP4ok6clYygzgY8CZh7TdBJxaVT8H/CvwLoAkm4ELgJ9tn/mzJMckOQb4MHAWsBm4sPWVJI3JogFQVZ8HHj6k7e+r6kBb3QtsaMtbgaur6jtV9XVgBji9vWaq6t6q+i5wdesrSRqTlTgH8BvAZ9ryemD/vG2zre2J2g+TZEeS6STTc3NzK1CeJGkhQwVAkncDB4BPHGxaoFsdof3wxqpdVTVVVVMTExPDlCdJOoJlXwaaZBvwWmBLVR38Yz4LbJzXbQPwQFt+onZJ0hgsawaQ5EzgncC5VfX4vE17gAuSHJ/kFGAT8C/AF4BNSU5JchyDE8V7hitdkjSMRWcASa4CXgGsSzILXMLgqp/jgZuSAOytqt+sqjuTXAPcxeDQ0EVV9X/te94K3AgcA1xZVXeuws8jSVqiRQOgqi5coPmKI/R/H/C+BdpvAG54UtVJklaNdwJLUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1KlFAyDJlUkeSvLVeW3PS3JTknva+4mtPUk+lGQmyR1JTpv3mW2t/z1Jtq3OjyNJWqqlzAA+Bpx5SNtO4Oaq2gTc3NYBzgI2tdcO4HIYBAZwCfALwOnAJQdDQ5I0HosGQFV9Hnj4kOatwO62vBs4b177x2tgL3BCkhcArwFuqqqHq+oR4CYODxVJ0ggt9xzA86vqQYD2fnJrXw/sn9dvtrU9UbskaUxW+iRwFmirI7Qf/gXJjiTTSabn5uZWtDhJ0g8tNwC+0Q7t0N4fau2zwMZ5/TYADxyh/TBVtauqpqpqamJiYpnlSZIWs9wA2AMcvJJnG3DdvPY3tKuBzgAea4eIbgReneTEdvL31a1NkjQmxy7WIclVwCuAdUlmGVzNcylwTZLtwP3A+a37DcDZwAzwOPAmgKp6OMl7gS+0fu+pqkNPLEuSRmjRAKiqC59g05YF+hZw0RN8z5XAlU+qOknSqvFOYEnq1KIzAElry+TO68e27/suPWds+9bKcwYgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE75MDhJSzauB9H5ELrV4QxAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6NVQAJPmdJHcm+WqSq5I8PckpSW5Nck+STyY5rvU9vq3PtO2TK/EDSJKWZ9kBkGQ98FvAVFWdChwDXAC8H7isqjYBjwDb20e2A49U1YuAy1o/SdKYDHsI6Fjgx5McCzwDeBB4JXBt274bOK8tb23rtO1bkmTI/UuSlmnZAVBV/wH8EXA/gz/8jwG3AY9W1YHWbRZY35bXA/vbZw+0/icd+r1JdiSZTjI9Nze33PIkSYsY5hDQiQz+r/4U4CeAZwJnLdC1Dn7kCNt+2FC1q6qmqmpqYmJiueVJkhYxzCGgVwFfr6q5qvoe8CngF4ET2iEhgA3AA215FtgI0LY/F3h4iP1LkoYwTADcD5yR5BntWP4W4C7gFuB1rc824Lq2vKet07Z/tqoOmwFIkkZjmHMAtzI4mftF4Cvtu3YB7wQuTjLD4Bj/Fe0jVwAntfaLgZ1D1C1JGtJQ/yJYVV0CXHJI873A6Qv0/TZw/jD7kyStHO8ElqROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTQwVAkhOSXJvka0n2JXlZkucluSnJPe39xNY3ST6UZCbJHUlOW5kfQZK0HMPOAP4U+Luq+hng54F9wE7g5qraBNzc1gHOAja11w7g8iH3LUkawrIDIMlzgF8CrgCoqu9W1aPAVmB367YbOK8tbwU+XgN7gROSvGDZlUuShjLMDOCFwBzw0SS3J/lIkmcCz6+qBwHa+8mt/3pg/7zPz7Y2SdIYDBMAxwKnAZdX1UuB/+WHh3sWkgXa6rBOyY4k00mm5+bmhihPknQkwwTALDBbVbe29WsZBMI3Dh7aae8Pzeu/cd7nNwAPHPqlVbWrqqaqampiYmKI8iRJR7LsAKiq/wT2J/np1rQFuAvYA2xrbduA69ryHuAN7WqgM4DHDh4qkiSN3rFDfv5twCeSHAfcC7yJQahck2Q7cD9wfut7A3A2MAM83vpKksZkqACoqi8BUwts2rJA3wIuGmZ/kqSV453AktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVPD3gcgdWty5/XjLkEaijMASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTvk0UB3VfCKntHzOACSpUwaAJHVq6ABIckyS25N8uq2fkuTWJPck+WSS41r78W19pm2fHHbfkqTlW4kZwNuBffPW3w9cVlWbgEeA7a19O/BIVb0IuKz1kySNyVABkGQDcA7wkbYe4JXAta3LbuC8try1rdO2b2n9JUljMOwM4IPA7wHfb+snAY9W1YG2Pgusb8vrgf0Abftjrb8kaQyWHQBJXgs8VFW3zW9eoGstYdv8792RZDrJ9Nzc3HLLkyQtYpgZwMuBc5PcB1zN4NDPB4ETkhy8v2AD8EBbngU2ArTtzwUePvRLq2pXVU1V1dTExMQQ5UmSjmTZAVBV76qqDVU1CVwAfLaqfg24BXhd67YNuK4t72nrtO2frarDZgCSpNFYjfsA3glcnGSGwTH+K1r7FcBJrf1iYOcq7FuStEQr8iiIqvoc8Lm2fC9w+gJ9vg2cvxL7kyQNzzuBJalTBoAkdcoAkKRO+ThoSWveOB/7fd+l54xt36vNGYAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pSPg14F43x0rSQtlTMASeqUASBJnTIAJKlTBoAkdcoAkKROLTsAkmxMckuSfUnuTPL21v68JDcluae9n9jak+RDSWaS3JHktJX6ISRJT94wM4ADwDuq6iXAGcBFSTYDO4Gbq2oTcHNbBzgL2NReO4DLh9i3JGlIyw6Aqnqwqr7Ylv8b2AesB7YCu1u33cB5bXkr8PEa2AuckOQFy65ckjSUFTkHkGQSeClwK/D8qnoQBiEBnNy6rQf2z/vYbGs79Lt2JJlOMj03N7cS5UmSFjB0ACR5FvDXwG9X1X8dqesCbXVYQ9WuqpqqqqmJiYlhy5MkPYGhAiDJjzH44/+JqvpUa/7GwUM77f2h1j4LbJz38Q3AA8PsX5K0fMNcBRTgCmBfVf3JvE17gG1teRtw3bz2N7Srgc4AHjt4qEiSNHrDPAzu5cCvA19J8qXW9vvApcA1SbYD9wPnt203AGcDM8DjwJuG2LckaUjLDoCq+kcWPq4PsGWB/gVctNz9SZJWlncCS1KnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0a5h+Fl6SnvMmd149lv/ddes6q78MZgCR1ygCQpE4ZAJLUqZEHQJIzk9ydZCbJzlHvX5I0MNIASHIM8GHgLGAzcGGSzaOsQZI0MOqrgE4HZqrqXoAkVwNbgbtWY2fjOnsvSUeDUR8CWg/sn7c+29okSSM26hlAFmirH+mQ7AB2tNX/SXL3qld1dFgHfHPcRaxBjsvCHJeFHTXjkvcP9fGfWkqnUQfALLBx3voG4IH5HapqF7BrlEUdDZJMV9XUuOtYaxyXhTkuC3NcftSoDwF9AdiU5JQkxwEXAHtGXIMkiRHPAKrqQJK3AjcCxwBXVtWdo6xBkjQw8mcBVdUNwA2j3u9TgIfFFua4LMxxWZjjMk+qavFekqSnHB8FIUmdMgDWmMUelZHk4iR3Jbkjyc1JlnS519FuqY8QSfK6JJWkiys9ljIuSX61/c7cmeQvR13jOCzhv6OfTHJLktvbf0tnj6POsasqX2vkxeDE+L8BLwSOA74MbD6kz68Az2jLbwE+Oe6618K4tH7PBj4P7AWmxl33WhgXYBNwO3BiWz953HWvkXHZBbylLW8G7ht33eN4OQNYW37wqIyq+i5w8FEZP1BVt1TV4211L4N7KZ7qFh2X5r3AHwLfHmVxY7SUcXkz8OGqegSgqh4acY3jsJRxKeA5bfm5HHI/Ui8MgLXlyT4qYzvwmVWtaG1YdFySvBTYWFWfHmVhY7aU35cXAy9O8k9J9iY5c2TVjc9SxuUPgNcnmWVwVeLbRlPa2uI/Cbm2LPqojB90TF4PTAG/vKoVrQ1HHJckTwMuA944qoLWiKX8vhzL4DDQKxjMFv8hyalV9egq1zZOSxmXC4GPVdUfJ3kZ8BdtXL6/+uWtHc4A1pZFH5UBkORVwLuBc6vqOyOqbZwWG5dnA6cCn0tyH3AGsKeDE8FL+X2ZBa6rqu9V1deBuxkEwlPZUsZlO3ANQFX9M/B0Bs8J6ooBsLYs+qiMdqjjzxn88e/heC4sMi5V9VhVrauqyaqaZHBu5Nyqmh5PuSOzlEer/C2DCwdIso7BIaF7R1rl6C1lXO4HtgAkeQmDAJgbaZVrgAGwhlTVAeDgozL2AddU1Z1J3pPk3NbtA8CzgL9K8qUkT/lnKS1xXLqzxHG5EfhWkruAW4Dfrapvjafi0VjiuLwDeHOSLwNXAW+sdklQT7wTWJI65QxAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1Kn/B9gjMtbpSD+tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "mu, sigma = 200, 25\n",
    "x = similarity\n",
    "n, bins, patches = plt.hist(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
