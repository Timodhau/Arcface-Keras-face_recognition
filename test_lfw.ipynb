{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import isfile\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "from random import shuffle\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.initializers import Constant\n",
    "import tensorflow as tf\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.models import Model\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (112,96,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lfw_list(index_file_path):\n",
    "    with open(index_file_path, 'rb') as index_file:\n",
    "        split_lines = [ln.decode().strip().split('\\t') for ln in index_file]\n",
    "    return split_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13233\n",
      "5999\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('../datasets/lfw/bbox_masked/')))\n",
    "\n",
    "\n",
    "data = get_lfw_list('../datasets/lfw/pairs.txt')\n",
    "data = data[2:]\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John_Bolton', '6', '7']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122e522e1c244116a77655e70b0689af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[5555])\n",
    "test_X = []\n",
    "pair1 = []\n",
    "pair2 = []\n",
    "label = []\n",
    "\n",
    "for pairs in tqdm(data):\n",
    "    if len(pairs)==3:\n",
    "        number = str(pairs[1])\n",
    "        if len(number)==1:number = '000'+number\n",
    "        if len(number)==2:number = '00'+number\n",
    "        if len(number)==3:number = '0'+number\n",
    "        pair1_path = str(pairs[0])+':'+number+'.jpg'\n",
    "        number = str(pairs[2])\n",
    "        if len(number)==1:number = '000'+number\n",
    "        if len(number)==2:number = '00'+number\n",
    "        if len(number)==3:number = '0'+number\n",
    "        pair2_path = str(pairs[0])+':'+number+'.jpg'\n",
    "        \n",
    "        pair1.append(pair1_path)\n",
    "        pair2.append(pair2_path)\n",
    "        label.append(1)\n",
    "        \n",
    "        test_X.append(pair1_path)\n",
    "        test_X.append(pair2_path)\n",
    "    if len(pairs)==4:\n",
    "        number = str(pairs[1])\n",
    "        if len(number)==1:number = '000'+number\n",
    "        if len(number)==2:number = '00'+number\n",
    "        if len(number)==3:number = '0'+number\n",
    "        pair1_path = str(pairs[0])+':'+number+'.jpg'\n",
    "        number = str(pairs[3])\n",
    "        if len(number)==1:number = '000'+number\n",
    "        if len(number)==2:number = '00'+number\n",
    "        if len(number)==3:number = '0'+number\n",
    "        pair2_path = str(pairs[2])+':'+number+'.jpg'\n",
    "        \n",
    "        pair1.append(pair1_path)\n",
    "        pair2.append(pair2_path)\n",
    "        label.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=pair1, columns=['pair1'])\n",
    "df['pair2'] = pair2\n",
    "df['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair1</th>\n",
       "      <th>pair2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akhmed_Zakayev:0001.jpg</td>\n",
       "      <td>Akhmed_Zakayev:0003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akhmed_Zakayev:0002.jpg</td>\n",
       "      <td>Akhmed_Zakayev:0003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amber_Tamblyn:0001.jpg</td>\n",
       "      <td>Amber_Tamblyn:0002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anders_Fogh_Rasmussen:0001.jpg</td>\n",
       "      <td>Anders_Fogh_Rasmussen:0003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anders_Fogh_Rasmussen:0001.jpg</td>\n",
       "      <td>Anders_Fogh_Rasmussen:0004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            pair1                           pair2  label\n",
       "0         Akhmed_Zakayev:0001.jpg         Akhmed_Zakayev:0003.jpg      1\n",
       "1         Akhmed_Zakayev:0002.jpg         Akhmed_Zakayev:0003.jpg      1\n",
       "2          Amber_Tamblyn:0001.jpg          Amber_Tamblyn:0002.jpg      1\n",
       "3  Anders_Fogh_Rasmussen:0001.jpg  Anders_Fogh_Rasmussen:0003.jpg      1\n",
       "4  Anders_Fogh_Rasmussen:0001.jpg  Anders_Fogh_Rasmussen:0004.jpg      1"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(len(df)):\n",
    "    pair=[]\n",
    "    pair.append(df['pair1'].iloc[i])\n",
    "    pair.append(df['pair2'].iloc[i])\n",
    "    test.append(pair)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import img_to_array,array_to_img\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n",
    ")\n",
    "\n",
    "def strong_aug(p=0.7):\n",
    "    return Compose([\n",
    "        #RandomRotate90(),\n",
    "        #Flip(),\n",
    "        #HorizontalFlip(),\n",
    "        #OneOf([\n",
    "        #    IAAAdditiveGaussianNoise()\n",
    "        #], p=0.3),\n",
    "        #OneOf([\n",
    "        #    MotionBlur(p=0.3),\n",
    "        #    MedianBlur(blur_limit=1, p=0.3),\n",
    "        #    Blur(blur_limit=1, p=0.3),\n",
    "        #], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=30, p=0.5,border_mode=0),\n",
    "        #CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.35),\n",
    "        #OneOf([\n",
    "        #    IAASharpen(),\n",
    "        #    IAAEmboss(),\n",
    "        #], p=0.3),\n",
    "    ], p=p)\n",
    "\n",
    "aug = strong_aug(p=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = shape\n",
    "\n",
    "def read_cropped_image(p, augment):\n",
    "    \"\"\"\n",
    "    @param p : the name of the picture to read\n",
    "    @param augment: True/False if data augmentation should be performed\n",
    "    @return a numpy array with the transformed image\n",
    "    \"\"\"\n",
    "    # Read the image, transform to black and white and comvert to numpy array\n",
    "    img   = read_raw_image(p)#.convert('L')\n",
    "    img   = img_to_array(img)\n",
    "        \n",
    "    img   = img.astype('uint8')\n",
    "    \n",
    "    \n",
    "    if img.shape[2] == 1:\n",
    "        img = np.stack((img[..., 0],) * 3, axis=-1)\n",
    "    \n",
    "    if augment:\n",
    "        augmented = aug(image=img)\n",
    "        img = augmented['image']\n",
    "\n",
    "    \n",
    "    img = cv2.resize(img,(img_shape[1],img_shape[0]))\n",
    "\n",
    "    img   = img.astype('float64')\n",
    "    #img = img.astype('uint8')\n",
    "    # Normalize to zero mean and unit variance\n",
    "    img  -= np.mean(img, keepdims=True)\n",
    "    img  /= np.std(img, keepdims=True) #+ K.epsilon()\n",
    "    #img = img.reshape(img.shape[0],img.shape[1],1)\n",
    "    \n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_metric(x1, x2):\n",
    "    return np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))\n",
    "\n",
    "\n",
    "def cal_accuracy(y_score, y_true):\n",
    "    y_score = np.asarray(y_score)\n",
    "    y_true = np.asarray(y_true)\n",
    "    best_acc = 0\n",
    "    best_th = 0\n",
    "    for i in range(len(y_score)):\n",
    "        th = y_score[i]\n",
    "        y_test = (y_score >= th)\n",
    "        acc = np.mean((y_test == y_true).astype(int))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_th = th\n",
    "    return (best_acc, best_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL HEREEEE\n",
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "backbone = ResNet50(input_shape=shape, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Angular_loss import *\n",
    "\n",
    "num_classes = 10575\n",
    "\n",
    "model = create_model(shape,backbone,64e-2,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arcface-MASKED-UNMASKED-112x96-201-5.285-0.839.model', 'Arcface-UNMASKED-MASKED-0.9650-0.23.model', 'Arcface-MASKED-UNMASKED-112x96-151-5.293-0.839.model', 'Arcface-MASKED-112x96-09-13.037-0.019.model', 'Arcface-UNMASKED-112x96-77-3.744-0.890.model', '.ipynb_checkpoints', 'Arcface-MASKED-112x112-14-12.856-0.016-20190421_212644.model', 'Arcface-UNMASKED-112x96-78-3.754-0.890.model', 'Cosface-UNMASKED-112x112-69-3.238-0.863-20190422_174305.model', 'Arcface-MASKED-112x112-41-5.166-0.834-20190429_173333.model', 'Arcface-MASKED-112x112-23-12.932-0.020-20190424_110959.model', 'Arcface-MASKED-UNMASKED-112x96-138-5.289-0.840.model', 'Arcface-UNMASKED-112x112-3.826-0.888.model']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('../state-of-art/model-checkpoint/Casia/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Unmasked\n",
    "model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-UNMASKED-112x96-77-3.744-0.890.model')\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-UNMASKED-112x96-78-3.754-0.890.model')\n",
    "#Model Masked\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-MASKED-112x96-09-13.037-0.019.model')\n",
    "#Model Unmasked/Masked\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-MASKED-UNMASKED-112x96-138-5.289-0.840.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-UNMASKED-112x112-3.826-0.888.model')\n",
    "#Model 3\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-UNMASKED-MASKED-0.9650-0.23.model')\n",
    "#Model 1\n",
    "#model.load_weights('../state-of-art/model-checkpoint/Casia/Arcface-MASKED-112x112-23-12.932-0.020-20190424_110959.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 112, 96, 3)        0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 4, 3, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_with__arcface_loss_7 ( (None, 10575)             21657600  \n",
      "=================================================================\n",
      "Total params: 45,253,504\n",
      "Trainable params: 45,196,288\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 112, 96, 3)        0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 4, 3, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2048)              8192      \n",
      "=================================================================\n",
      "Total params: 23,595,904\n",
      "Trainable params: 23,538,688\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_name = model.layers[-2].name\n",
    "model = Model(inputs=model.input,\n",
    "                        outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestingGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs,batch_size=32, dim=(112,112) ,n_classes=num_classes,n_channels=3,\n",
    "                 shuffle=False,augmentation=False):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.list_IDs = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.augmentation = augmentation\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor((len(self.list_IDs) / self.batch_size) ))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        \n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = read_cropped_image(ID,self.augmentation)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as pil_image\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "TRAIN_PATH = '../datasets/lfw/bbox_masked/'\n",
    "\n",
    "def expand_path(p):\n",
    "    if isfile(TRAIN_PATH + str(p)): return TRAIN_PATH + str(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "def read_raw_image(p):\n",
    "    img = pil_image.open(expand_path(p))\n",
    "    #if p in rotate: img = img.rotate(180)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n",
      "5998\n",
      "11998\n"
     ]
    }
   ],
   "source": [
    "tr = os.listdir('../datasets/lfw/bbox_masked/')\n",
    "final_test = []\n",
    "\n",
    "for pairs in test:\n",
    "    if pairs[0] in tr:\n",
    "        if pairs[1] in tr:\n",
    "            final_test.append(pairs[0])\n",
    "            final_test.append(pairs[1])\n",
    "\n",
    "print(len(test))\n",
    "print(len(test_X))\n",
    "print(len(final_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11998/11998 [==============================] - 190s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "params = {'dim': (img_shape[0],img_shape[1]),\n",
    "          'batch_size': 1,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': False\n",
    "             }\n",
    "\n",
    "testing_generator = TestingGenerator(final_test ,**params,augmentation=False)\n",
    "\n",
    "features = model.predict_generator(\n",
    "        generator=testing_generator,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_metric(x1, x2):\n",
    "    return np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "label = []\n",
    "\n",
    "for i in range(0,len(features),2):\n",
    "    feature1 = features[i]\n",
    "    feature2 = features[i+1]\n",
    "    distance = cosin_metric(feature1,feature2)\n",
    "    similarity.append(distance)\n",
    "    if final_test[i].split(':')[0]==final_test[i+1].split(':')[0]:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n",
      "5999\n",
      "[0.74365675 0.67009586 0.74848217 ... 0.13878314 0.18135798 0.27580664]\n"
     ]
    }
   ],
   "source": [
    "print(len(similarity))\n",
    "print(len(label))\n",
    "similarity = np.absolute(similarity)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(len(similarity)):\n",
    "    if similarity[i]>threshold:\n",
    "        predicted = 1\n",
    "    else: predicted = 0\n",
    "    if predicted == label[i]:\n",
    "        accuracy += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9256542757126188\n"
     ]
    }
   ],
   "source": [
    "print(accuracy/len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
